receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:
    send_batch_size: 512
    timeout: 5s
  memory_limiter:
    check_interval: 2s
    limit_percentage: 80
    spike_limit_percentage: 25
  tail_sampling:
    decision_wait: 10s
    num_traces: 10000
    expected_new_traces_per_sec: 1500
    policies:
      - name: errors
        type: status_code
        status_code:
          status_codes: [ERROR]
      - name: slow-requests
        type: latency
        latency:
          threshold: 300ms

exporters:
  logging:
    loglevel: debug
  otlphttp/prometheus:
    endpoint: http://prometheus:9090/api/v1/otlp
  otlphttp/grafana:
    endpoint: http://tempo:4318/v1/traces
    tls:
      insecure: true
  prometheusremotewrite:
    endpoint: http://prometheus:9090/api/v1/write

connectors:
  spanmetrics:
    dimensions:
      - name: http.method
      - name: http.route
    metrics_flush_interval: 15s
    histogram:
      explicit:
        buckets: [25ms, 50ms, 100ms, 200ms, 500ms, 1s]

service:
  telemetry:
    logs:
      level: "info"
  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, tail_sampling, batch]
      exporters: [otlphttp/grafana, logging, spanmetrics]
    metrics/spanmetrics:
      receivers: [spanmetrics]
      exporters: [otlphttp/prometheus, prometheusremotewrite]
